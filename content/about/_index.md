---
title: 'Feng-Ting Liao'
date: 2024-07-16T17:17:20+02:00
draft: false
url: "/about/"
params:
    math: true
---

[[resume](https://ftliao.github.io/data/240805_FengTingLiao_resume.pdf)][[cv](https://ftliao.github.io/data/240805_FengTingLiao_CV.pdf)][[googlescholar](https://scholar.google.com/citations?user=wQtfX2cAAAAJ&hl=en)][[linkedin](https://www.linkedin.com/in/fengtingliao)]


<!-- I am a Senior Research Scientist at MediaTek Research, working on large language models, deep reinforcement learning in chip design, diffusion models, speech processing, and representation learning with publications at ICML, EACL, ASRU. -->

<!-- seasoned technical professional with a strong background in machine learning, natural language processing, and chip design. My expertise lies not only in developing cutting-edge technologies but also in effectively communicating complex ideas and orchestrating cross-functional collaborations to bring innovative products to market. -->

I am a Senior Research Scientist at MediaTek Research with a track record on large language models, deep reinforcement learning in chip design, diffusion models, speech processing, and representation learning with publications at ICML, EACL, ASRU. 

My expertise lies not only in developing cutting-edge technologies but also in effectively communicating complex ideas and synergizing cross-functional collaborations to bring innovative products to market. With a team of talented researchers and seasoned professionals across legal, product, and marketing, I co-created and productized **[BreeXe](https://huggingface.co/spaces/MediaTek-Research/Demo-MR-Breexe-8x7B), a commercialized LLM beating GPT3.5 on both knowledge and chat capabilities in Traditional Chinese**, and open-sourced **[Breeze](https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v1_0), a 7B LLM with >11k downloads**, for supporting research and entrepreneural efforts in LLMs in Traditional Chinese speaking communities.

To get in touch, please email to *fengting.liao19[AT]gmail.com*

<!-- Prior to  -->


### Work Experience
- **Senior Research Scientist | MediaTek Research**, Nov 2020 - Present, Taipei Taiwan
- **Research Engineer | Umbo Computer Vision**, Mar 2019 - Feb 2020, Taipei Taiwan
- **Data Science Intern | Burberry**, Dec 2018, London, UK
- **Postdoctoral Research Assistant | University of Oxford**, Jan - Dec 2018, Oxford, UK



### Selected Publications
- Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Multi-modal Text Recognition, Hsu et al., Preprint ,2024 ([paper](https://arxiv.org/pdf/2405.14259), [code](https://github.com/mtkresearch/generative-fusion-decoding))
- Breeze-7B Technical Report, MediaTek Research, 2024 ([paper](https://arxiv.org/abs/2403.02712), [model weight](https://huggingface.co/MediaTek-Research/Breeze-7B-Base-v1_0))
- Image generation with shortest path diffusion, Das et al., ICML, 2023 ([paper](https://arxiv.org/abs/2306.00501), [code](https://github.com/mtkresearch/shortest-path-diffusion))
- Zero-Shot Domain-Sensitive Speech Recognition with Prompt-Conditioning Fine-Tuning, Liao et al., ASRU, 2023 ([paper](https://arxiv.org/pdf/2307.10274), [code](https://github.com/mtkresearch/clairaudience))
- Advancing the evaluation of traditional chinese language models: Towards a comprehensive benchmark suite, Hsu et al., Preprint, 2023 ([paper](https://arxiv.org/abs/2309.08448), [code](https://huggingface.co/datasets/MediaTek-Research/TCEval-v2))
- Meta-Learning with MAML on Trees, Garcia et al., EACL workshop: Adapt-NLP, 2021 ([paper](https://arxiv.org/pdf/2103.04691))
- First dark matter search results from the LUX-ZEPLIN (LZ) experiment, LZ Collaboration, Physical review letters, 2023 ([paper](https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.131.041002))
- Projected WIMP sensitivity of the LUX-ZEPLIN dark matter experiment, The LZ Collaboration, Physical Review D, 2020 ([paper](https://link.aps.org/accepted/10.1103/PhysRevD.101.052002))
- LUX-ZEPLIN (LZ) Technical Design Report, The LZ Collaboration, 2017 ([paper](https://arxiv.org/abs/1703.09144))
- LUX-ZEPLIN (LZ) conceptual design report, The LZ Collaboration, 2015 ([paper](https://arxiv.org/pdf/1509.02910))


### Education


- DPhil in Particle Physics, University of Oxford, 2013-2018
- B.Sc. in Electrophysics, National Chiao Tung University, 2008-2012


### Mentorship

<!-- - Mentorship -->
- Tzu-Lin Kuo (M.S student at NTU CSIE)
- Yung-Chieh Chan (M.S student at Stanford)
- Ren-Chu Wang (M.S student at GeorgiaTech)
- Chien-Yi Yang (PhD student at UCSD)

<!-- Just don't work in hugo -->
<!-- <style>
  .flex-container {
    display: flex;
    justify-content: space-between;
  }
</style> -->
<!-- <div class="flex-container">
  <span>DPhil in Particle Physics, University of Oxford</span>
  <span>2013-2018</span>
</div>
<div class="flex-container">
  <span>B.Sc. in Electrophysics, National Chiao Tung University</span>
  <span>2008-2012</span>
</div> -->
